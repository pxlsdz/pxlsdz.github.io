<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"pxlsdz.github.io","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="使用numpy函数和numpy矩阵&#x2F;向量运算">
<meta property="og:type" content="article">
<meta property="og:title" content="Python基础与Numpy 吴恩达深度学习">
<meta property="og:url" content="https://pxlsdz.github.io/2020/01/15/Python%E5%9F%BA%E7%A1%80%E4%B8%8ENumpy-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="pxlsdz的博客">
<meta property="og:description" content="使用numpy函数和numpy矩阵&#x2F;向量运算">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://q45jvnp3f.bkt.clouddn.com/image2vector_kiank.png">
<meta property="og:image" content="https://raw.githubusercontent.com/pxlsdz/MarkDown-images/master/image2vector_kiank.png">
<meta property="article:published_time" content="2020-01-15T11:25:28.000Z">
<meta property="article:modified_time" content="2020-03-01T05:00:27.578Z">
<meta property="article:author" content="sdz">
<meta property="article:tag" content="numpy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://q45jvnp3f.bkt.clouddn.com/image2vector_kiank.png">

<link rel="canonical" href="https://pxlsdz.github.io/2020/01/15/Python%E5%9F%BA%E7%A1%80%E4%B8%8ENumpy-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>Python基础与Numpy 吴恩达深度学习 | pxlsdz的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">pxlsdz的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">分享，笔记</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">32</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">17</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">56</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="search-pop-overlay">
  <div class="popup search-popup">
      <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

  </div>
</div>

  </div>
</div>
    </header>

    

  <a href="https://github.com/pxlsdz" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://pxlsdz.github.io/2020/01/15/Python%E5%9F%BA%E7%A1%80%E4%B8%8ENumpy-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="sdz">
      <meta itemprop="description" content="个人博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="pxlsdz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python基础与Numpy 吴恩达深度学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-15 19:25:28" itemprop="dateCreated datePublished" datetime="2020-01-15T19:25:28+08:00">2020-01-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-01 13:00:27" itemprop="dateModified" datetime="2020-03-01T13:00:27+08:00">2020-03-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">python基础</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/01/15/Python%E5%9F%BA%E7%A1%80%E4%B8%8ENumpy-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/01/15/Python%E5%9F%BA%E7%A1%80%E4%B8%8ENumpy-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>10 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="使用numpy函数和numpy矩阵-向量运算"><a href="#使用numpy函数和numpy矩阵-向量运算" class="headerlink" title="使用numpy函数和numpy矩阵/向量运算"></a><strong>使用numpy函数和numpy矩阵/向量运算</strong></h2><a id="more"></a>

<h3 id="sigmoid-函数-np-exp"><a href="#sigmoid-函数-np-exp" class="headerlink" title="sigmoid 函数, np.exp()"></a><strong>sigmoid 函数, np.exp()</strong></h3><p>In fact, if “$x = (x_1, x_2, …, x_n)$”  is a row vector then $np.exp(x)$ will apply the exponential function to every element of x. The output will thus be:<br>$$<br>np.exp(x) = (e^{x_1}, e^{x_2}, …, e^{x_n})<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">print(np.exp(x))<span class="comment">#结果是(exp(1), exp(2), exp(3))</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[  2.71828183   7.3890561   20.08553692]</span><br></pre></td></tr></table></figure>

<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 向量化的例子</span></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="keyword">print</span> (x + <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[4 5 6]</span><br></pre></td></tr></table></figure>

<hr>
<p>x现在可以是<strong>实数，向量或矩阵</strong>。 我们在numpy中使用的表示这些形状（矢量，矩阵等）的数据结构称为numpy数组。<br>$$<br>\text{For } x \in \mathbb{R}^n \text{,} sigmoid(x) = sigmoid\begin{pmatrix}<br>    x_1  \<br>    x_2  \<br>    …  \<br>    x_n  \<br>\end{pmatrix} = \begin{pmatrix}<br>    \frac{1}{1+e^{-x_1}}  \<br>    \frac{1}{1+e^{-x_2}}  \<br>    …  \<br>    \frac{1}{1+e^{-x_n}}  \<br>\end{pmatrix}\tag{1}<br>$$</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Compute the sigmoid of x</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- A scalar or numpy array of any size</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">    s -- sigmoid(x)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 1 line of code)</span></span><br><span class="line">    s = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">sigmoid(x) <span class="comment">#x为列表的化就会报错</span></span><br><span class="line"><span class="comment">#array([0.73105858, 0.88079708, 0.95257413])</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Sigmoid-梯度"><a href="#Sigmoid-梯度" class="headerlink" title="Sigmoid 梯度"></a><strong>Sigmoid 梯度</strong></h3><p>需要计算梯度以使用反向传播来优化损耗函数</p>
<p>您将需要计算梯度以使用反向传播来优化损耗函数。公式为：<br>$$<br>sigmoid_derivative(x) = \sigma’(x) = \sigma(x) (1 - \sigma(x))\tag{2}<br>$$<br>两步编写此函数的代码：</p>
<ol>
<li>将s设置为x的sigmoid形。 您可能会发现sigmoid（x）函数很有用。</li>
<li>计算𝜎’（𝑥）=𝑠（1-𝑠）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: sigmoid_derivative</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_derivative</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算sigmoid型函数相对于其输入x的梯度（也称为斜率或导数）。</span></span><br><span class="line"><span class="string">  您可以将sigmoid型函数的输出存储到变量中，然后使用它来计算梯度。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">     参数：</span></span><br><span class="line"><span class="string">     x-标量或numpy数组</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     返回：</span></span><br><span class="line"><span class="string">     ds-您计算出的梯度。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    s = sigmoid(x)</span><br><span class="line">    ds = s * (<span class="number">1</span> - s)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ds</span><br></pre></td></tr></table></figure>

<p>求导</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"sigmoid_derivative(x) = "</span> + str(sigmoid_derivative(x)))</span><br><span class="line"><span class="comment">#结果：sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]</span></span><br></pre></td></tr></table></figure>



<h3 id="Reshaping-arrays"><a href="#Reshaping-arrays" class="headerlink" title="Reshaping arrays"></a><strong>Reshaping arrays</strong></h3><p>深度学习中使用的两个常见的numpy函数是np.shape和np.reshape（）。</p>
<ul>
<li>X.shape用于获取矩阵/向量X的形状（尺寸）。</li>
<li>X.reshape（…）用于将X重塑为其他尺寸。</li>
</ul>
<p>例如，在计算机科学中，图像由形状为（𝑙𝑒𝑛𝑔𝑡ℎ，ℎ𝑒𝑖𝑔ℎ𝑡，𝑑𝑒𝑝𝑡ℎ= 3）的3D数组表示。 但是，当您读取图像作为算法的输入时，会将其转换为形状为（𝑙𝑒𝑛𝑔𝑡ℎ∗ℎ𝑒𝑖𝑔ℎ𝑡∗ 3,1）的向量。 换句话说，您将3D阵列“展开”或重塑为1D向量。</p>
<p><img src="http://q45jvnp3f.bkt.clouddn.com/image2vector_kiank.png" alt="t图像转化向量"></p>
<p><img src="https://raw.githubusercontent.com/pxlsdz/MarkDown-images/master/image2vector_kiank.png" alt="图片"></p>
<p>练习：实现image2vector（），它接受形状（长度，高度，depth=3）的输入，并返回形状（长度*高度* 3，1）的向量。 例如，如果要将形状为（a，b，c）的数组v整形为形状为（a * b，c）的向量，则可以执行以下操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">v = v.reshape((v.shape[<span class="number">0</span>]*v.shape[<span class="number">1</span>], v.shape[<span class="number">2</span>])) </span><br><span class="line"><span class="comment"># v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c</span></span><br></pre></td></tr></table></figure>
<p>请不要将图像的尺寸硬编码为常数。 而是使用image.shape [0]等查找所需的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image2vector</span><span class="params">(image)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    image -- a numpy array of shape (length, height, depth)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    v -- a vector of shape (length*height*depth, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 1 line of code)</span></span><br><span class="line">    v = image.reshape(image.shape[<span class="number">0</span>] * image.shape[<span class="number">1</span>] * image.shape[<span class="number">2</span>], <span class="number">1</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">image = np.array([[[ <span class="number">0.67826139</span>,  <span class="number">0.29380381</span>],</span><br><span class="line">        [ <span class="number">0.90714982</span>,  <span class="number">0.52835647</span>],</span><br><span class="line">        [ <span class="number">0.4215251</span> ,  <span class="number">0.45017551</span>]],</span><br><span class="line"></span><br><span class="line">       [[ <span class="number">0.92814219</span>,  <span class="number">0.96677647</span>],</span><br><span class="line">        [ <span class="number">0.85304703</span>,  <span class="number">0.52351845</span>],</span><br><span class="line">        [ <span class="number">0.19981397</span>,  <span class="number">0.27417313</span>]],</span><br><span class="line"></span><br><span class="line">       [[ <span class="number">0.60659855</span>,  <span class="number">0.00533165</span>],</span><br><span class="line">        [ <span class="number">0.10820313</span>,  <span class="number">0.49978937</span>],</span><br><span class="line">        [ <span class="number">0.34144279</span>,  <span class="number">0.94630077</span>]]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"image2vector(image) = "</span> + str(image2vector(image)))</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">image2vector(image) &#x3D; [[0.67826139]</span><br><span class="line"> [0.29380381]</span><br><span class="line"> [0.90714982]</span><br><span class="line"> [0.52835647]</span><br><span class="line"> [0.4215251 ]</span><br><span class="line"> [0.45017551]</span><br><span class="line"> [0.92814219]</span><br><span class="line"> [0.96677647]</span><br><span class="line"> [0.85304703]</span><br><span class="line"> [0.52351845]</span><br><span class="line"> [0.19981397]</span><br><span class="line"> [0.27417313]</span><br><span class="line"> [0.60659855]</span><br><span class="line"> [0.00533165]</span><br><span class="line"> [0.10820313]</span><br><span class="line"> [0.49978937]</span><br><span class="line"> [0.34144279]</span><br><span class="line"> [0.94630077]]</span><br></pre></td></tr></table></figure>

<h3 id="标准化行"><a href="#标准化行" class="headerlink" title="标准化行"></a><strong>标准化行</strong></h3><p>我们在机器学习和深度学习中使用的另一种常用技术是对数据进行规范化。 通常会导致更好的性能，因为归一化后梯度下降的收敛速度更快。 在这里，通过归一化，我们的意思是将x更改为$ \frac{x}{| x|} $（将x的每个行向量除以其范数）</p>
<p>如果<br>$$<br>x =<br>\begin{bmatrix}<br>    0 &amp; 3 &amp; 4 \<br>    2 &amp; 6 &amp; 4 \<br>\end{bmatrix}\tag{3}<br>$$</p>
<p> 然后<br>$$<br>| x| = np.linalg.norm(x, axis = 1, keepdims = True) = \begin{bmatrix}<br>    5 \<br>    \sqrt{56} \<br>\end{bmatrix}\tag{4}<br>$$</p>
<p>接着        </p>
<p>$$<br>x_normalized = \frac{x}{| x|} = \begin{bmatrix}<br>    0 &amp; \frac{3}{5} &amp; \frac{4}{5} \<br>    \frac{2}{\sqrt{56}} &amp; \frac{6}{\sqrt{56}} &amp; \frac{4}{\sqrt{56}} \<br>\end{bmatrix}\tag{5}<br>$$</p>
<p>请注意，可以划分不同大小的矩阵，并且效果很好：这称为广播，下面会学习它。</p>
<p>练习：实现normalizeRows（）来规范化矩阵的行。 在将此函数应用于输入矩阵x之后，x的每一行应为单位长度（即长度1）的向量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalizeRows</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement a function that normalizes each row of the matrix x (to have unit length).</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    x -- A numpy matrix of shape (n, m)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    x -- The normalized (by row) numpy matrix. You are allowed to modify x.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    <span class="comment"># Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)</span></span><br><span class="line">    x_norm = np.linalg.norm(x, axis = <span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Divide x by its norm.</span></span><br><span class="line">    x = x / x_norm</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">6</span>, <span class="number">4</span>]])</span><br><span class="line">print(<span class="string">"normalizeRows(x) = "</span> + str(normalizeRows(x)))</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">normalizeRows(x) = [[<span class="number">0.</span>         <span class="number">0.6</span>        <span class="number">0.8</span>       ]</span><br><span class="line"> [<span class="number">0.13736056</span> <span class="number">0.82416338</span> <span class="number">0.54944226</span>]]</span><br></pre></td></tr></table></figure>

<p>在normalizeRows（）中，可以尝试打印x_norm和x的形状，然后重新运行评估。 会发现它们具有不同的形状。 鉴于x_norm采用x每行的范数，这是正常的。 因此，x_norm具有相同的行数，但只有1列。 那么，当将x除以x_norm时，它是如何工作的？ 这就是所谓的广播！</p>
<h2 id="广播"><a href="#广播" class="headerlink" title="广播"></a><strong>广播</strong></h2><p>在numpy中要理解的一个非常重要的概念是“广播”。 这对于在不同形状的数组之间执行数学运算非常有用。 </p>
<p>练习：使用numpy实现softmax函数。 可以将softmax视为算法需要对两个或多个类进行分类时使用的规范化函数。 </p>
<ul>
<li><p>$ \text{对于 } x \in \mathbb{R}^{1\times n} \text{,     } softmax(x) = softmax(\begin{bmatrix}<br>  x_1  &amp;&amp;<br>  x_2 &amp;&amp;<br>  …  &amp;&amp;<br>  x_n<br>\end{bmatrix}) = \begin{bmatrix}<br>   \frac{e^{x_1}}{\sum_{j}e^{x_j}}  &amp;&amp;<br>  \frac{e^{x_2}}{\sum_{j}e^{x_j}}  &amp;&amp;<br>  …  &amp;&amp;<br>  \frac{e^{x_n}}{\sum_{j}e^{x_j}}<br>\end{bmatrix} $ </p>
</li>
<li><p>$\text{对于每一个矩阵 } x \in \mathbb{R}^{m \times n} \text{,  $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: }$  </p>
</li>
<li><p>$$<br>  softmax(x) = softmax\begin{bmatrix}<br>  x_{11} &amp; x_{12} &amp; x_{13} &amp; \dots  &amp; x_{1n} \<br>  x_{21} &amp; x_{22} &amp; x_{23} &amp; \dots  &amp; x_{2n} \<br>  \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>x_{m1} &amp; x_{m2} &amp; x_{m3} &amp; \dots  &amp; x_{mn}<br>  \end{bmatrix} = \begin{bmatrix}<br>  \frac{e^{x_{11}}}{\sum_{j}e^{x_{1j}}} &amp; \frac{e^{x_{12}}}{\sum_{j}e^{x_{1j}}} &amp; \frac{e^{x_{13}}}{\sum_{j}e^{x_{1j}}} &amp; \dots  &amp; \frac{e^{x_{1n}}}{\sum_{j}e^{x_{1j}}} \<br>  \frac{e^{x_{21}}}{\sum_{j}e^{x_{2j}}} &amp; \frac{e^{x_{22}}}{\sum_{j}e^{x_{2j}}} &amp; \frac{e^{x_{23}}}{\sum_{j}e^{x_{2j}}} &amp; \dots  &amp; \frac{e^{x_{2n}}}{\sum_{j}e^{x_{2j}}} \<br>  \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>\frac{e^{x_{m1}}}{\sum_{j}e^{x_{mj}}} &amp; \frac{e^{x_{m2}}}{\sum_{j}e^{x_{mj}}} &amp; \frac{e^{x_{m3}}}{\sum_{j}e^{x_{mj}}} &amp; \dots  &amp; \frac{e^{x_{mn}}}{\sum_{j}e^{x_{mj}}}<br>  \end{bmatrix} = \begin{pmatrix}<br>  softmax\text{(first row of x)}  \<br>  softmax\text{(second row of x)} \<br>  …  \<br>softmax\text{(last row of x)} \<br>  \end{pmatrix}<br>  $$</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""Calculates the softmax for each row of the input x.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Your code should work for a row vector and also for matrices of shape (n, m).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    x -- A numpy matrix of shape (n,m)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    s -- A numpy matrix equal to the softmax of x, of shape (n,m)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 3 lines of code)</span></span><br><span class="line">    <span class="comment"># Apply exp() element-wise to x. Use np.exp(...).</span></span><br><span class="line">    x_exp = np.exp(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建向量x_sum，该向量求和x_exp的每一行。 使用np.sum（...，axis = 1，keepdims = True）</span></span><br><span class="line">    x_sum = np.sum(x_exp, axis = <span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute softmax(x) by dividing x_exp by x_sum. It should automatically use numpy broadcasting.</span></span><br><span class="line">    s = x_exp / x_sum</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([</span><br><span class="line">    [<span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">7</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span> ,<span class="number">0</span>]])</span><br><span class="line">print(<span class="string">"softmax(x) = "</span> + str(softmax(x)))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">softmax(x) &#x3D; [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04</span><br><span class="line">  1.21052389e-04]</span><br><span class="line"> [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04</span><br><span class="line">  8.01252314e-04]]</span><br></pre></td></tr></table></figure>

<p>如果在上面打印x_exp，x_sum和s的形状并重新运行评估单元，您将看到x_sum的形状为（2,1），而x_exp和s的形状为（2,5）。 x_exp / x_sum由于python广播而起作用。</p>
<h2 id="向量化代码"><a href="#向量化代码" class="headerlink" title="向量化代码"></a><strong>向量化代码</strong></h2><p>在深度学习中，您处理非常大的数据集。 因此，非计算最佳函数可能会成为算法中的巨大瓶颈，并可能导致模型运行一段时间。 为了确保代码在计算上高效，您将使用向量化。 例如，尝试说明点/外部/元素乘积的以下实现之间的区别。</p>
<p>普通实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x1 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">x2 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tic = time.process_time()</span><br><span class="line">dot = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(x1)):</span><br><span class="line">    dot+= x1[i]*x2[i]</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dot = "</span> + str(dot) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line">tic = time.process_time()</span><br><span class="line">outer = np.zeros((len(x1),len(x2))) <span class="comment"># we create a len(x1)*len(x2) matrix with only zeros</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(x1)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(x2)):</span><br><span class="line">        outer[i,j] = x1[i]*x2[j]</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"outer = "</span> + str(outer) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tic = time.process_time()</span><br><span class="line">mul = np.zeros(len(x1))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(x1)):</span><br><span class="line">    mul[i] = x1[i]*x2[i]</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"elementwise multiplication = "</span> + str(mul) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">W = np.random.rand(<span class="number">3</span>,len(x1)) <span class="comment"># Random 3*len(x1) numpy array</span></span><br><span class="line">tic = time.process_time()</span><br><span class="line">gdot = np.zeros(W.shape[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(W.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(x1)):</span><br><span class="line">        gdot[i] += W[i,j]*x1[j]</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"gdot = "</span> + str(gdot) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br></pre></td></tr></table></figure>



<p>（1）：np.dot()</p>
<p>如果碰到的是秩为1的数组，那么执行的是对应位置的元素相乘再相加;</p>
<p>如果遇到的是秩不为1的数组，那么执行的是矩阵相乘。但是需要注意的是矩阵与矩阵相乘是秩为2，矩阵和向量相乘秩为1。</p>
<p>（2)：np.multiply()表示的是数组和矩阵对应位置相乘，输出和输出的结果shape一致。</p>
<p>（3）：np.outer()(外积）</p>
<p>表示的是两个向量相乘，拿第一个向量的元素分别与第二个向量所有元素相乘得到结果的一行。</p>
<p>假设向量 a = [a0,  a1,  … , aM], b = [b0, b1, …, bN],   则 a<em>b =[[a0</em>b0, a0<em>b1, … ,a0</em>bM], [a1<em>b0, a1</em>b1, … , a1<em>bN], …. , [aM</em>b0, aM<em>b1, … , aM</em>bN]]; 注意：若 a，b 不为一维数组，则先将其变成一维数组，即可得 a(M,)和 b(N,) 这种形式。</p>
<p>（4）：*对数组执行的是对应位置相乘，对矩阵执行的是矩阵相乘。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">x1 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">x2 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">tic = time.process_time()</span><br><span class="line">dot = np.dot(x1,x2)</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dot = "</span> + str(dot) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line">tic = time.process_time()</span><br><span class="line">outer = np.outer(x1,x2)</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"outer = "</span> + str(outer) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line">tic = time.process_time()</span><br><span class="line">mul = np.multiply(x1,x2)</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"elementwise multiplication = "</span> + str(mul) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tic = time.process_time()</span><br><span class="line">dot = np.dot(W,x1)</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"gdot = "</span> + str(dot) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br></pre></td></tr></table></figure>



<p>两个输出结果是一样的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> ----- Computation time = <span class="number">0.0</span>ms</span><br><span class="line">outer = [[<span class="number">81</span> <span class="number">18</span> <span class="number">18</span> <span class="number">81</span>  <span class="number">0</span> <span class="number">81</span> <span class="number">18</span> <span class="number">45</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">81</span> <span class="number">18</span> <span class="number">45</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [<span class="number">18</span>  <span class="number">4</span>  <span class="number">4</span> <span class="number">18</span>  <span class="number">0</span> <span class="number">18</span>  <span class="number">4</span> <span class="number">10</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">18</span>  <span class="number">4</span> <span class="number">10</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [<span class="number">45</span> <span class="number">10</span> <span class="number">10</span> <span class="number">45</span>  <span class="number">0</span> <span class="number">45</span> <span class="number">10</span> <span class="number">25</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">45</span> <span class="number">10</span> <span class="number">25</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [<span class="number">63</span> <span class="number">14</span> <span class="number">14</span> <span class="number">63</span>  <span class="number">0</span> <span class="number">63</span> <span class="number">14</span> <span class="number">35</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">63</span> <span class="number">14</span> <span class="number">35</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [<span class="number">45</span> <span class="number">10</span> <span class="number">10</span> <span class="number">45</span>  <span class="number">0</span> <span class="number">45</span> <span class="number">10</span> <span class="number">25</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">45</span> <span class="number">10</span> <span class="number">25</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [<span class="number">81</span> <span class="number">18</span> <span class="number">18</span> <span class="number">81</span>  <span class="number">0</span> <span class="number">81</span> <span class="number">18</span> <span class="number">45</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">81</span> <span class="number">18</span> <span class="number">45</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [<span class="number">18</span>  <span class="number">4</span>  <span class="number">4</span> <span class="number">18</span>  <span class="number">0</span> <span class="number">18</span>  <span class="number">4</span> <span class="number">10</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">18</span>  <span class="number">4</span> <span class="number">10</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [<span class="number">45</span> <span class="number">10</span> <span class="number">10</span> <span class="number">45</span>  <span class="number">0</span> <span class="number">45</span> <span class="number">10</span> <span class="number">25</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">45</span> <span class="number">10</span> <span class="number">25</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>]]</span><br><span class="line"> ----- Computation time = <span class="number">0.0</span>ms</span><br><span class="line">elementwise multiplication = [<span class="number">81</span>  <span class="number">4</span> <span class="number">10</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">63</span> <span class="number">10</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">81</span>  <span class="number">4</span> <span class="number">25</span>  <span class="number">0</span>  <span class="number">0</span>]</span><br><span class="line"> ----- Computation time = <span class="number">0.0</span>ms</span><br><span class="line">gdot = [<span class="number">20.19795192</span> <span class="number">23.62425978</span> <span class="number">18.27514239</span>]</span><br><span class="line"> ----- Computation time = <span class="number">0.0</span>ms</span><br></pre></td></tr></table></figure>

<p>向量化的实现更加简洁高效。 对于更大的向量/矩阵，运行时间的差异变得更大。</p>
<p><strong>请注意</strong> np.dot（）执行矩阵矩阵或矩阵向量乘法。 这与np.multiply（）和<em>操作符（在Matlab / Octave中等效于。</em>）不同，后者执行逐元素乘法。</p>
<h3 id="实现L1和L2损失功能"><a href="#实现L1和L2损失功能" class="headerlink" title="实现L1和L2损失功能"></a><strong>实现L1和L2损失功能</strong></h3><p><strong>练习</strong>：实施L1损失的Numpy向量化版本。 您可能会发现函数abs（x）（x的绝对值）很有用。</p>
<p><strong>提醒</strong>：<br>-损失用于评估模型的性能。 损失越大，您的预测（$\hat{y}$）与真实值（$y$）的差异就越大。 在深度学习中，您可以使用诸如Gradient Descent之类的优化算法来训练模型并最大程度地降低成本。<br>-L1损失定义为：<br>$$<br>\begin{align<em>} &amp; L_1(\hat{y}, y) = \sum_{i=0}^m|y^{(i)} - \hat{y}^{(i)}| \end{align</em>}\tag{6}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L1</span><span class="params">(yhat, y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    yhat -- vector of size m (predicted labels)</span></span><br><span class="line"><span class="string">    y -- vector of size m (true labels)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    loss -- the value of the L1 loss function defined above</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 1 line of code)</span></span><br><span class="line">    loss = np.sum(np.abs(y - yhat))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yhat = np.array([<span class="number">.9</span>, <span class="number">0.2</span>, <span class="number">0.1</span>, <span class="number">.4</span>, <span class="number">.9</span>])</span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">print(<span class="string">"L1 = "</span> + str(L1(yhat,y)))<span class="comment">#L1 = 1.1</span></span><br></pre></td></tr></table></figure>

<hr>
<p><strong>练习</strong>：实施L2损失的Numpy矢量化版本。 有两种方法可以实现L2损失，但您可能会发现np.dot（）函数很有用。 提醒一下，如果$ x = [x_1，x_2，…，x_n] $，则<code>np.dot（x，x）</code>= $ \ sum_ {j = 0} ^ n x_j ^ {2} $。<br>$$<br>\begin{align<em>} &amp; L_2(\hat{y},y) = \sum_{i=0}^m(y^{(i)}  -\hat{y}^{(i)})^2\end{align</em>}\tag{7}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L2</span><span class="params">(yhat, y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    yhat -- vector of size m (predicted labels)</span></span><br><span class="line"><span class="string">    y -- vector of size m (true labels)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    loss -- the value of the L2 loss function defined above</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 1 line of code)</span></span><br><span class="line">    loss = np.dot((y - yhat),(y - yhat).T)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yhat = np.array([<span class="number">.9</span>, <span class="number">0.2</span>, <span class="number">0.1</span>, <span class="number">.4</span>, <span class="number">.9</span>])</span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">print(<span class="string">"L2 = "</span> + str(L2(yhat,y)))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L2 &#x3D; 0.43</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong>-向量化在深度学习中非常重要。 它提供了计算效率和清晰度。 -已查看L1和L2损失。 -您熟悉许多numpy函数，例如np.sum，np.dot，np.multiply，np.maximum等。</p>

    </div>

    
    
    
	
    <div style="text-align:center;color: #ccc;font-size:14px;">
------------- 本文结束 <i class="fa fa-heart-o"></i> 感谢您的阅读-------------
</div>
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>sdz
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://pxlsdz.github.io/2020/01/15/Python%E5%9F%BA%E7%A1%80%E4%B8%8ENumpy-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="Python基础与Numpy 吴恩达深度学习">https://pxlsdz.github.io/2020/01/15/Python基础与Numpy-吴恩达深度学习/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/numpy/" rel="tag"><i class="fa fa-tag"></i> numpy</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/01/14/MFC-QQ%E5%AE%9E%E7%8E%B0/" rel="prev" title="MFC-QQ">
      <i class="fa fa-chevron-left"></i> MFC-QQ
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/01/17/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E5%90%8E%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A-Course-1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%B8%89%E5%91%A8%E4%BD%9C%E4%B8%9A-%E5%B8%A6%E6%9C%89%E4%B8%80%E4%B8%AA%E9%9A%90%E8%97%8F%E5%B1%82%E7%9A%84%E5%B9%B3%E9%9D%A2%E6%95%B0%E6%8D%AE%E5%88%86%E7%B1%BB/" rel="next" title="吴恩达课后编程作业 Course 1 神经网络和深度学习 - 第三周作业 -  带有一个隐藏层的平面数据分类">
      吴恩达课后编程作业 Course 1 神经网络和深度学习 - 第三周作业 -  带有一个隐藏层的平面数据分类 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用numpy函数和numpy矩阵-向量运算"><span class="nav-number">1.</span> <span class="nav-text">使用numpy函数和numpy矩阵&#x2F;向量运算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sigmoid-函数-np-exp"><span class="nav-number">1.1.</span> <span class="nav-text">sigmoid 函数, np.exp()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid-梯度"><span class="nav-number">1.2.</span> <span class="nav-text">Sigmoid 梯度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reshaping-arrays"><span class="nav-number">1.3.</span> <span class="nav-text">Reshaping arrays</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#标准化行"><span class="nav-number">1.4.</span> <span class="nav-text">标准化行</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#广播"><span class="nav-number">2.</span> <span class="nav-text">广播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量化代码"><span class="nav-number">3.</span> <span class="nav-text">向量化代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#实现L1和L2损失功能"><span class="nav-number">3.1.</span> <span class="nav-text">实现L1和L2损失功能</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="sdz"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">sdz</p>
  <div class="site-description" itemprop="description">个人博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/pxlsdz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;pxlsdz" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/sdz20172133" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;sdz20172133" rel="noopener" target="_blank"><i class="fa fa-fw fa-codiepie"></i>CSDN</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sdz</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">281k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">4:16</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'pAM5gCGYUGBwBF62VmECeV0o-gzGzoHsz',
      appKey     : 'myehhFCNOsN4ClPFSLov1xKd',
      placeholder: "欢迎畅所欲言",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  <!-- 页面点击小红心 -->

      <script type="text/javascript" src="/js/clicklove.js"></script>

</body>
</html>
